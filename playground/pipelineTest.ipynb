{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pip\n",
    "\n",
    "\n",
    "def import_or_install(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        pip.main(['install', package])\n",
    "\n",
    "\n",
    "packages = ['PyQt6', 'nltk', 'pyvis', 'matplotlib_inline', 'matplotlib', 'gensim.corpora', 'gensim.utils',\n",
    "            'gensim.models', 'matplotlib_inline.pyplot', 'pandas', 'numpy', 'umap', 'sqlite3', 'spacy',\n",
    "            'win32com.client', 'datetime', 'pyvis.network', 'matplotlib.pyplot', 'plotly.graph_objects', 'scipy',\n",
    "            'networkx', 'dash', 'gensim', 'logging', 'warnings', 'nltk.corpus']\n",
    "\n",
    "for package in packages:\n",
    "    import_or_install(package)\n",
    "\n",
    "print('done with package installation')\n",
    "\n",
    "import nltk\n",
    "import sqlite3\n",
    "\n",
    "nltk.download('stopwords')\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import numpy as np\n",
    "import win32com.client\n",
    "from datetime import datetime, timedelta\n",
    "from dash import html\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from textblob import TextBlob\n",
    "import random\n",
    "import dash\n",
    "import json\n",
    "from dash.dependencies import Input, Output\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "from dash import dash_table\n",
    "import dash_cytoscape as cyto\n",
    "\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# stopword definitions for later sections\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def drop_nas_df(df):\n",
    "    nan_value = float(\"NaN\")\n",
    "    df.replace(\"\", nan_value, inplace=True)\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "\n",
    "class NetworkMessages:\n",
    "    def __init__(self):\n",
    "        self.messages = []\n",
    "\n",
    "    def lemmatize_with_postag(self, sentence):\n",
    "        # Get each words Part of speech ( verb, noun etc) then pass it with the word to a lemmatizer. Then put the lemmatized word back into the Pandas DF row\n",
    "        sent = TextBlob(sentence)\n",
    "        tag_dict = {\"J\": 'a',\n",
    "                    \"N\": 'n',\n",
    "                    \"V\": 'v',\n",
    "                    \"R\": 'r'}\n",
    "        words_and_tags = [(w, tag_dict.get(pos[0], 'n')) for w, pos in sent.tags]\n",
    "        lemmatized_list = [wd.lemmatize(tag) for wd, tag in words_and_tags]\n",
    "        return \" \".join(lemmatized_list)\n",
    "\n",
    "    def normalize_df_col(self, col):\n",
    "        self.messages[col] = self.messages[col].apply(lambda x: x.lower())\n",
    "        self.messages[col] = self.messages[col].str.replace(r'[^\\w\\s]+', '')  # (?:\\w+)\n",
    "        self.messages[col] = self.messages[col].replace(r'\\n', ' ', regex=True)\n",
    "        self.messages[col] = self.messages[col].replace(r'\\r', ' ', regex=True)\n",
    "        self.messages[col] = self.messages[col].replace(r'_', '', regex=True)\n",
    "        self.messages[col] = self.messages[col].str.strip()\n",
    "        self.messages[col] = self.messages[col].apply(lambda x: ' '.join([word for word in x.split() if word not in (\n",
    "            stopwords)]))  # should look at tokenizing instead of splitting maybe?\n",
    "        self.messages[col] = self.messages[col].apply(self.lemmatize_with_postag)\n",
    "        return self.messages\n",
    "\n",
    "    def build_topics(self, topic_count, col):\n",
    "        tfidf = TfidfVectorizer(ngram_range=(1, 2), sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1',\n",
    "                                stop_words='english')\n",
    "        dtm = tfidf.fit_transform(self.messages[col])\n",
    "        nmf_model = NMF(n_components=topic_count, random_state=42)\n",
    "        nmf_model.fit(dtm)\n",
    "        topics_dict = {}\n",
    "        for index, topic in enumerate(nmf_model.components_):\n",
    "            topic_text_string = str([tfidf.get_feature_names_out()[i] for i in topic.argsort()[-topic_count:]])\n",
    "            v = {index: str(topic_text_string)}\n",
    "            topics_dict.update(v)\n",
    "\n",
    "        topic_text_df = pd.Series(topics_dict).to_frame()\n",
    "        topic_text_df.reset_index(level=0, inplace=True)\n",
    "        topic_text_df = topic_text_df.rename(columns={0: \"topic_text\", 'index': \"topic\"})\n",
    "        self.topic_results = nmf_model.transform(dtm)\n",
    "        self.messages['topic'] = self.topic_results.argmax(axis=1)\n",
    "        topic_colors = {}\n",
    "        for x in range(topic_count):\n",
    "            hex_color = \"%06x\" % random.randint(0, 0xFFFFFF)\n",
    "            hex_color = \"#\" + hex_color\n",
    "            topic_colors.update({x: x, x: hex_color, })\n",
    "\n",
    "        self.topic_color_df = pd.DataFrame(topic_colors.items(), columns=['topic', 'color'])\n",
    "        self.topic_color_df = self.topic_color_df.merge(topic_text_df, left_on=['topic', 'topic'],\n",
    "                                                        right_on=['topic', 'topic'], how='left')\n",
    "        return self.messages, self.topic_color_df, self.topic_results\n",
    "\n",
    "    def merge_topic_colors(self):\n",
    "        # THIS CHUNK GENERATES TOPIC COLORS AND MERGES IT WITH THE MASTER TABLEs\n",
    "        print('merging topic colors')\n",
    "        self.messages = self.messages.merge(self.topic_color_df, left_on=['topic', 'topic'],\n",
    "                                            right_on=['topic', 'topic'], how='left')\n",
    "        self.recipients = self.messages.merge(self.recipients, left_on=['entryID', 'entryID'],\n",
    "                                              right_on=['entryID', 'entryID'], how='left')\n",
    "        self.recipients = self.recipients.reset_index(drop=True)\n",
    "        return self.messages, self.recipients\n",
    "\n",
    "    def group_recipients(self):\n",
    "        # must include color\n",
    "        self.recipients = self.recipients.groupby(['sender', 'recipient', 'topic', 'color']).size()\n",
    "        self.recipients = self.recipients.to_frame(name='size').reset_index()\n",
    "        self.recipients = self.recipients.loc[self.recipients['size'] != 1]\n",
    "        return self.recipients\n",
    "\n",
    "    def pipeline_topic_colors(self):\n",
    "        self.messages, self.recipients = self.merge_topic_colors()\n",
    "        self.recipients = self.group_recipients()\n",
    "        self.recipients = drop_nas_df(self.recipients)\n",
    "        return self.messages, self.recipients\n",
    "\n",
    "    def generate_node_dataframe(self):\n",
    "        print(\"Generating node DF\")\n",
    "        df_node_temp = self.recipients\n",
    "        # build node list off of to/from table. Adding a new feature called count driven by node edge counts\n",
    "        df1 = df_node_temp['sender']\n",
    "        df2 = df_node_temp['recipient']\n",
    "        df_nodes = df1.append(df2)\n",
    "        df_nodes.reset_index()\n",
    "        df_nodes = df_nodes.to_frame()\n",
    "        df_nodes = df_nodes.rename(columns={0: \"individuals\"})\n",
    "        df_nodes = df_nodes['individuals'].value_counts()\n",
    "        df_nodes = df_nodes.to_frame()\n",
    "        self.df_nodes = df_nodes.rename(columns={'individuals': \"count\"})\n",
    "        self.df_nodes.index.name = 'individual'\n",
    "        self.df_nodes.reset_index(inplace=True)\n",
    "        return self.df_nodes\n",
    "\n",
    "    def generate_edges_dataframe(self):\n",
    "        print(\"Generating edges DF\")\n",
    "        edges_table = [self.recipients[\"sender\"], self.recipients[\"recipient\"], self.recipients['topic'],\n",
    "                       self.recipients['color'], self.recipients['size']]\n",
    "        headers = [\"source\", \"target\", \"topic\", \"color\", \"size\"]\n",
    "        self.df_edges = pd.concat(edges_table, axis=1, keys=headers)\n",
    "        return self.df_edges\n",
    "\n",
    "    def generate_node_and_edge_tables(self):\n",
    "        self.generate_node_dataframe()\n",
    "        self.generate_edges_dataframe()\n",
    "        return self.df_nodes, self.df_edges\n",
    "\n",
    "\n",
    "class OutlookEmails(NetworkMessages):\n",
    "    def __init__(self, folder_number):\n",
    "        super().__init__()\n",
    "        self.folder_number = folder_number\n",
    "        self.outlook_connection = win32com.client.Dispatch(\"Outlook.Application\").GetNamespace(\"MAPI\")\n",
    "        folder_contents = self.outlook_connection.GetDefaultFolder(self.folder_number)\n",
    "        self.messages = folder_contents.Items\n",
    "\n",
    "    def build_network_df(self):\n",
    "        print('building core network arrays')\n",
    "        # Build core tables\n",
    "        pd_messages = []\n",
    "        pd_recipients = []\n",
    "        for message in list(self.messages):\n",
    "            try:\n",
    "                recipients_list = message.Recipients\n",
    "                recipients_cleaned = \"\"\n",
    "                for recipient in recipients_list:\n",
    "                    pd_recipients.append({\n",
    "                        \"entryID\": str(message.EntryID),\n",
    "                        \"sender\": str(message.Sender),\n",
    "                        \"recipient\": str(recipient),\n",
    "                    })\n",
    "\n",
    "                pd_messages.append({\n",
    "                    \"entryID\": str(message.EntryID),\n",
    "                    \"conversationID\": str(message.ConversationID),\n",
    "                    \"conversationIndex\": str(message.ConversationIndex),\n",
    "                    \"createTime\": str(message.CreationTime),\n",
    "                    \"recievedTime\": str(message.ReceivedTime),\n",
    "                    \"ConversationTopic\": str(message.ConversationTopic),\n",
    "                    \"subject\": str(message.Subject),\n",
    "                    \"body\": str(message.body)\n",
    "                })\n",
    "            except:\n",
    "                print(\"error processing message =  \" + str(recipients_list))\n",
    "\n",
    "        self.messages = pd.DataFrame(pd_messages)\n",
    "        self.recipients = pd.DataFrame(pd_recipients)\n",
    "        return self.messages, self.recipients\n",
    "\n",
    "    def filter_days_back(self, date_range):\n",
    "        print('applying outlook filter')\n",
    "        # filter messages processed by the last X days\n",
    "        received_dt = datetime.now() - timedelta(days=date_range)\n",
    "        received_dt = received_dt.strftime('%m/%d/%Y %H:%M %p')\n",
    "        self.messages = self.messages.Restrict(\"[ReceivedTime] >= '\" + received_dt + \"'\")\n",
    "        return self.messages\n",
    "\n",
    "    # def build_graph_tables(self):\n",
    "\n",
    "\n",
    "def build_network_nodes(df_nodes):\n",
    "    print('building network node array')\n",
    "    nodes = set()\n",
    "    cy_nodes = []\n",
    "    for index, row in df_nodes.iterrows():\n",
    "        individual, bins = row['individual'], row['log_count']\n",
    "        nodes.add(individual)\n",
    "        cy_nodes.append({\"data\": {\"id\": individual, \"label\": individual, 'weight': bins*10, }})\n",
    "    return cy_nodes\n",
    "\n",
    "def build_network_edges(df_edges):\n",
    "    print('building network edge array')\n",
    "    cy_edges = []\n",
    "    for index, row in df_edges.iterrows():\n",
    "        source, target, topic, weight, topic_color = row['source'], row['target'], row['topic'], row['size'], row['color']\n",
    "        cy_edges.append({\n",
    "            'data': {\n",
    "                'source': source,\n",
    "                'target': target,\n",
    "                'topic': topic,\n",
    "                'weight': weight,\n",
    "                'topic_color': topic_color\n",
    "            }\n",
    "        })\n",
    "    return cy_edges\n",
    "\n",
    "\n",
    "def generate_folder_network_tables(folder, days_back):\n",
    "    inbox_emails = OutlookEmails(folder)\n",
    "    inbox_emails.filter_days_back(days_back)\n",
    "    inbox_emails.build_network_df()\n",
    "    inbox_emails.normalize_df_col('body')\n",
    "    inbox_emails.build_topics(15, 'body')\n",
    "    inbox_emails.pipeline_topic_colors()\n",
    "    inbox_emails.generate_node_and_edge_tables()\n",
    "    return inbox_emails"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "inbox_six = generate_folder_network_tables(6, 100)\n",
    "print(inbox_six.messages)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# define stylesheet\n",
    "n_stylesheet = [\n",
    "    {\n",
    "        \"selector\": 'node',  #For all nodes\n",
    "        'style': {\n",
    "            \"opacity\": 0.9,\n",
    "            \"height\": \"data(weight)\",\n",
    "            'width': 'data(weight)',\n",
    "            \"label\": \"data(label)\",  #Label of node to display\n",
    "            \"background-color\": \"#07ABA0\",  #node color\n",
    "            \"color\": \"#008B80\"  #node label color\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"selector\": 'edge',  #For all edges\n",
    "        \"style\": {\n",
    "            \"target-arrow-color\": \"#C5D3E2\",  #Arrow color\n",
    "            \"target-arrow-shape\": \"triangle\",  #Arrow shape\n",
    "            \"line-color\": \"data(topic_color)\",  #edge color\n",
    "            'arrow-scale': 2,  #Arrow size\n",
    "            'curve-style': 'bezier'  #Default curve-If it is style, the arrow will not be displayed, so specify it\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "page_styles = {\n",
    "    'pre': {\n",
    "        'border': 'thin lightgrey solid',\n",
    "        'overflowX': 'scroll',\n",
    "        'min-height': '50px'\n",
    "    }\n",
    "}\n",
    "\n",
    "inbox_six.df_nodes['log_count'] = np.log(inbox_six.df_nodes['count'])\n",
    "\n",
    "\n",
    "cy_nodes = build_network_nodes(inbox_six.df_nodes)\n",
    "cy_edges = build_network_edges(inbox_six.df_edges)\n",
    "\n",
    "\n",
    "topic_color_df = inbox_six.topic_color_df\n",
    "edge_legend = inbox_six.topic_color_df[['topic','color']]\n",
    "\n",
    "\n",
    "cyto.load_extra_layouts()\n",
    "app = dash.Dash(__name__)\n",
    "#app.config['TESTING'] = True\n",
    "server = app.server\n",
    "\n",
    "app.layout = html.Div(children=[\n",
    "    html.H4(children='Communication patters'),\n",
    "\n",
    "    html.Div(\n",
    "        children=[\n",
    "            html.Div(children=[\n",
    "            cyto.Cytoscape(\n",
    "                id='cytoscape',\n",
    "                elements=cy_edges + cy_nodes,\n",
    "                style={\n",
    "                    'height': '95vh',\n",
    "                    'width': '100%'\n",
    "                },\n",
    "                 layout={'name': 'grid'},\n",
    "                stylesheet=n_stylesheet\n",
    "            )], style={'width': '50%'}),\n",
    "            html.Div(children=[\n",
    "                    dcc.Dropdown(id='dropdown_topic',\n",
    "                 options=[{'label': topic.capitalize(), 'value': topic}\n",
    "                         for topic in ['0', '1', '2', '3', '4']\n",
    "                         ]\n",
    "                 ),\n",
    "\n",
    "    dcc.Dropdown(\n",
    "        id='dropdown-update-layout',\n",
    "        options=[\n",
    "            {'label': 'random',\n",
    "             'value': 'random'},\n",
    "            {'label': 'grid',\n",
    "             'value': 'grid'},\n",
    "            {'label': 'circle',\n",
    "             'value': 'circle'},\n",
    "            {'label': 'concentric',\n",
    "             'value': 'concentric'},\n",
    "            {'label': 'breadthfirst - Hiearchy',\n",
    "             'value': 'breadthfirst'},\n",
    "            {'label': 'klay - Force Directed',\n",
    "             'value': 'klay'},\n",
    "            {'label': 'cose - Force Directed',\n",
    "             'value': 'cose'},\n",
    "            {'label': 'cose-bilkent - Force Directed',\n",
    "             'value': 'cose-bilkent'},\n",
    "            {'label': 'cola - Force Directed',\n",
    "             'value': 'cola'},\n",
    "            {'label': 'spread - Force Directed',\n",
    "             'value': 'spread'},\n",
    "            {'label': 'dagre - Hiearchy',\n",
    "             'value': 'dagre'}\n",
    "        ], value='circle'\n",
    "    ),\n",
    "                html.H4(children='NodeData'),\n",
    "                html.P(id='cytoscape_element_info_output'),\n",
    "                html.P(id='cytoscape-tapEdgeData-output'),\n",
    "                html.H4(children='Legend'),\n",
    "                dash_table.DataTable(\n",
    "                    data=edge_legend.to_dict('records'),\n",
    "                    columns=[{\"name\": i, \"id\": i} for i in edge_legend.columns],\n",
    "                    style_cell={'textAlign': 'left'},\n",
    "                    style_data_conditional=[\n",
    "                        {'if': {'row_index': i, 'column_id': 'color'},\n",
    "                         'background-color': edge_legend['color'][i],\n",
    "                         'color': edge_legend['color'][i]} for i in range(edge_legend.shape[0])\n",
    "                    ]\n",
    "                     )\n",
    "        ], style={'width': '50%'})\n",
    "        ], style={'display': 'flex', 'flex-direction': 'row'}),\n",
    "\n",
    "                dash_table.DataTable(\n",
    "                    data=topic_color_df.to_dict('records'),\n",
    "                    columns=[{\"name\": i, \"id\": i} for i in topic_color_df.columns],\n",
    "                    style_cell={'textAlign': 'left'},\n",
    "                    style_data_conditional=[\n",
    "                        {'if': {'row_index': i, 'column_id': 'color'},\n",
    "                         'background-color': topic_color_df['color'][i],\n",
    "                         'color': topic_color_df['color'][i]} for i in range(topic_color_df.shape[0])\n",
    "                    ]\n",
    "                     )\n",
    "])\n",
    "\n",
    "\n",
    "@app.callback(Output('cytoscape', 'layout'),\n",
    "              Input('dropdown-update-layout', 'value'))\n",
    "def update_layout(layout):\n",
    "        return {\n",
    "            'name': layout,\n",
    "        }\n",
    "\n",
    "\n",
    "@app.callback(Output('cytoscape_element_info_output', 'children'),\n",
    "              Input('cytoscape', 'tapNodeData'))\n",
    "def displayTapNodeData(data):\n",
    "    if data:\n",
    "        return \"You recently clicked/tapped node: \" + data['label']\n",
    "\n",
    "\n",
    "@app.callback(Output('cytoscape-tapEdgeData-output', 'children'),\n",
    "              Input('cytoscape', 'tapEdgeData'))\n",
    "def displayTapEdgeData(data):\n",
    "    if data:\n",
    "        return json.dumps(data, indent=2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}